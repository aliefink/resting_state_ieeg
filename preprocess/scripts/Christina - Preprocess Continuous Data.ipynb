{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Continuous Data - Resting State\n",
    "10/01/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore, linregress, ttest_ind, ttest_rel, ttest_1samp\n",
    "import pandas as pd\n",
    "from mne.preprocessing.bads import _find_outliers\n",
    "import os \n",
    "import joblib\n",
    "import emd\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/christinamaher/Documents/GitHub/LFPAnalysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LFPAnalysis import lfp_preprocess_utils, sync_utils, analysis_utils, nlx_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify root directory for un-archived data and results \n",
    "base_dir = '/Users/christinamaher/Documents/Github/resting_state_ieeg' # this is the root directory for most un-archived data and results \n",
    "\n",
    "subject_id = 'MS018'\n",
    "\n",
    "# I have saved most of my raw data in the 'projects directory'\n",
    "neural_dir = f'{base_dir}/preprocess/raw_data/{subject_id}'\n",
    "anat_dir = f'{base_dir}/anat'\n",
    "save_dir = f'{base_dir}preprocess/clean_data/{subject_id}'\n",
    "os.makedirs(save_dir,exist_ok = True) #added so you don't have to manually make subject folders in clean_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>January 01, 2001  19:00:21 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>Not available</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>276 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1024.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>512.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>MS018.edf</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:10:17 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawEDF | MS018.edf, 276 x 631040 (616.2 s), ~1.30 GB, data loaded>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf_files = glob(f'{neural_dir}/*.edf')\n",
    "\n",
    "mne_data = mne.io.read_raw_edf(edf_files[0], preload=True)\n",
    "mne_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check one channel data\n",
    "plt.plot(mne_data._data[0,:4999])\n",
    "plt.title(\"Raw iEEG, electrode 0, samples 0-4999\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Anat Recon Info - check all elecs are present in data + recon sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the electrode localization data\n",
    "anat_file = glob(f'{anat_dir}/{subject_id}_labels.csv')[0]\n",
    "elec_locs = pd.read_csv(anat_file)\n",
    "# Sometimes there's extra columns with no entries: \n",
    "elec_locs = elec_locs[elec_locs.columns.drop(list(elec_locs.filter(regex='Unnamed')))]\n",
    "elec_locs = elec_locs.dropna(axis=0, how = 'all') #some recons have a bunch of empty rows at the end \n",
    "elec_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_locs.label # pulls electrode names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix edf channel names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mne_names, unmatched_names, unmatched_seeg = lfp_preprocess_utils.match_elec_names(mne_data.ch_names, elec_locs.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name_dict = {x:y for (x,y) in zip(mne_data.ch_names, new_mne_names)}\n",
    "new_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the mne data according to the localization data\n",
    "mne_data.rename_channels(new_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_seeg #make sure there are no unmatched names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_names = list(elec_locs.label.str.lower())\n",
    "sum([ch not in mne_data.ch_names for ch in anat_names]) #if there are no missing channels, sum = 0. if sum >0, find the missing elecs\n",
    "print([ch for ch in mne_data.ch_names if ch not in anat_names ]) #print extra channels in mne_data.ch_names and make sure none of them are neural channels (will be EEG etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, there is surface EEG data that we should separately indicate from the sEEG:\n",
    "right_seeg_names = [i for i in mne_data.ch_names if i.startswith('r')]\n",
    "left_seeg_names = [i for i in mne_data.ch_names if i.startswith('l')]\n",
    "print(f'We have a total of', len(left_seeg_names), 'left &', len(right_seeg_names), 'right sEEG electrodes')\n",
    "print(f'We have a total of {len(left_seeg_names) + len(right_seeg_names)} sEEG electrodes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_chans = list(set(mne_data.ch_names)^set(left_seeg_names+right_seeg_names)) # it is either called DC1 or research\n",
    "mne_data.drop_channels(drop_chans) #number of chans should = number of seegs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set channel types:\n",
    "sEEG_mapping_dict = {f'{x}':'seeg' for x in left_seeg_names+right_seeg_names}\n",
    "mne_data.set_channel_types(sEEG_mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make montage (convert mm to m)\n",
    "\n",
    "montage = mne.channels.make_dig_montage(ch_pos=dict(zip(elec_locs.label, \n",
    "                                                        elec_locs[['mni_x', 'mni_y', 'mni_z']].to_numpy(dtype=float)/1000)),\n",
    "                                        coord_frame='mni_tal')\n",
    "\n",
    "mne_data.set_montage(montage, match_case=False, on_missing='warn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notch filter line noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify line noise\n",
    "mne_data.info['line_freq'] = 60\n",
    "\n",
    "# Notch out 60 Hz noise and harmonics \n",
    "mne_data.notch_filter(freqs=(60, 120, 180, 240))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all patients should be resampled to 500 Hz\n",
    "resample_sr = 500\n",
    "mne_data.resample(sfreq=resample_sr, npad='auto', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad Channel Removal (manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick out any bad channels missed by automatic screening (visual inspection as a reference), or restore channels that were erroneously deemed bad. You have to press the \"power\" button twice (once for the plot and once for the panel beneath it) when you're done so that you're manual changes are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "fig = mne_data.plot(start=0, duration=120, n_channels=50, scalings=mne_data._data.max()/20)\n",
    "fig.fake_keypress('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data.info['bads'] #sanity check that bads info saved\n",
    "len(mne_data.info['bads']) # number of bad electrodes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save raw LFP data\n",
    "Notch filtered and resampled with bad elecs indicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### important - check anat file to see if manual examination has a space in column name!\n",
    "\n",
    "#define oob elecs as bad before saving out lfp file \n",
    "oob_elec = [elec_locs['label'].iloc[ind].lower() for ind, data in elec_locs['Manual Examination'].str.lower().items() if data=='oob']\n",
    "oob_elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ch= mne_data.info['bads']\n",
    "bad_ch = bad_ch + oob_elec\n",
    "mne_data.info['bads'] = list(np.unique(bad_ch)) #updated so no duplicates in bad elecs\n",
    "mne_data.info['bads'] # make sure an WM referenced pairs that include these channels is excluded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data.save(f'{save_dir}/{subject_id}_raw_ieeg.fif',overwrite=True) #updated to add subject name to file & save to clean_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rereference data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WM REF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anode_list, cathode_list, drop_wm_channels, oob_channels = lfp_preprocess_utils.wm_ref(mne_data=mne_data, \n",
    "                                                                                elec_path=anat_file, \n",
    "                                                                                unmatched_seeg = unmatched_seeg,\n",
    "                                                                                bad_channels=mne_data.info['bads'],\n",
    "                                                                                      site = 'MSSM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clean_anode_cathode_lists(al, cl, bc):\n",
    "    \"\"\"\n",
    "    This function takes two lists of electrode names, 'al' and 'cl', and returns their cleaned version (eliminating electrodes that have been marked as OOB or noisy)\n",
    "\n",
    "    Args:\n",
    "        al (list of strings): anode list output from wm_ref().\n",
    "        cl (list of strings): cathode list output from wm_ref().\n",
    "        bc (list of strings): electrode list containing the names of all electrodes that were identified as OOB and noisy.\n",
    "\n",
    "    Returns:\n",
    "        anode_list_clean (list of strings): all clean in-brain anode electrodes\n",
    "        cathode_list_clean (list of strings): all clean in-brain cathode electrodes\n",
    "        removed_cathode_list (list of strings): cathodes that are removed to align with the clean anode list.\n",
    "    \"\"\"\n",
    "    anode_list_clean = []\n",
    "    removed_anode_index = []\n",
    "    for i, ch in enumerate(al):\n",
    "\n",
    "        if ch not in bc:  # You should have 'bad_ch' defined elsewhere\n",
    "            anode_list_clean.append(ch)\n",
    "        else:\n",
    "            removed_anode_index.append(i)\n",
    "\n",
    "    cathode_list_update = [cl[i] for i in range(len(cl)) if i not in removed_anode_index]\n",
    "    removed_cathode_list = [cathode_list[i] for i in range(len(cathode_list)) if i in removed_anode_index]\n",
    "\n",
    "    cathode_list_clean = []\n",
    "    for ch in cathode_list_update:\n",
    "        if ch not in bc:  # You should have 'bad_ch' defined elsewhere\n",
    "            cathode_list_clean.append(ch)\n",
    "\n",
    "    return anode_list_clean, cathode_list_clean, removed_cathode_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anode_list_clean, cathode_list_clean, removed_cathode_list = create_clean_anode_cathode_lists(al=anode_list, cl=cathode_list, bc=bad_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data_wm_reref = mne.set_bipolar_reference(mne_data, \n",
    "                      anode=anode_list, \n",
    "                      cathode=cathode_list,\n",
    "                      copy=True)\n",
    "\n",
    "mne_data_wm_reref #none of the bad channels should be rereferenced (see above) - should we drop these before saving?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data.drop_channels(mne_data.info['bads']) # now make sure the bad channels (OOB and noisy) are dropped the bad ones\n",
    "mne_data_wm_reref.drop_channels(drop_wm_channels)\n",
    "mne_data_wm_reref.drop_channels(removed_cathode_list) # you need to drop any that still remain at this point (otherwise they will remain in the dataframe as a single, non-rereferenced elec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start annotating, press 'Add new label' in the bottom panel. Then left click and drag around window of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "# use the epoch code to select only the WM referenced pairs\n",
    "fig = mne_data_wm_reref.plot(start=2, duration=50, n_channels=20,scalings=mne_data._data.max()/20 ) # plot all channels at once\n",
    "fig.fake_keypress(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function to eliminate need to specifically define good epochs! \n",
    "\n",
    "def join_good_segs(mne_data):\n",
    "    #creates indices of good epochs after labeling bad times manually, then crops good epochs and joins data \n",
    "    \n",
    "    ### get good times: \n",
    "    good_start = list([mne_data_wm_reref.first_time]) #first timepoint in recording (should be 0)\n",
    "    good_end = []\n",
    "    \n",
    "    for annot in mne_data.annotations:\n",
    "        bad_start = mne_data.time_as_index(annot['onset']) #onset is start time of bad epoch \n",
    "        # ^ start time of bad epoch converted to index, then subtract 1 for end of good epoch\n",
    "        bad_end = mne_data.time_as_index(annot['onset'] + annot['duration']) #onset + duration = end time of bad epoch\n",
    "        # ^ end time of bad epoch converted to index \n",
    "        # must get bad start and end as indices so you can +-1 for good epochs - cannot +-1 using time only indexes\n",
    "\n",
    "        good_end.append(mne_data.times[bad_start - 1]) #the start time of a bad epoch is the end of a good epoch - 1\n",
    "        good_start.append(mne_data.times[bad_end+1]) #the end time of a bad epoch is the start of a good epoch +1 index\n",
    "        #convert to integers before appending - indexing np arrays later is annoying\n",
    "                          \n",
    "    good_end.append(mne_data.times[mne_data.last_samp]) #index of last timepoint in recording (should = mne_data.n_times)\n",
    "    \n",
    "    ### get good data epochs and concatenate \n",
    "    good_segs = []\n",
    "    for start,end in list(zip(good_start,good_end)):\n",
    "        good_segs.append(mne_data.copy().crop(tmin=float(start), tmax=float(end),\n",
    "                include_tmax=True))\n",
    "    \n",
    "    return mne.concatenate_raws(good_segs)\n",
    "    \n",
    "#derived from: \n",
    "    # source: https://mne.discourse.group/t/removing-time-segments-from-raw-object-without-epoching/4169/2\n",
    "    # source: https://github.com/mne-tools/mne-python/blob/maint/1.5/mne/io/base.py#L681-L742\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data_wm_reref_clean = join_good_segs(mne_data_wm_reref)\n",
    "mne_data_wm_reref_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save reref data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_data_wm_reref_clean.save(f'{save_dir}/{subject_id}_wm_ref_ieeg.fif',overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
