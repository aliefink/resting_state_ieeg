{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f3f704",
   "metadata": {},
   "source": [
    "# Epoching for Continuous Data \n",
    "Created: 03/14/2024 by A Fink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f0a829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore, linregress, ttest_ind, ttest_rel, ttest_1samp\n",
    "import pandas as pd\n",
    "from mne.preprocessing.bads import _find_outliers\n",
    "import os \n",
    "import joblib\n",
    "import re\n",
    "import datetime\n",
    "import scipy\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfe0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d1db186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/alexandrafink/Documents/GitHub/LFPAnalysis/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "577cdfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LFPAnalysis import lfp_preprocess_utils, sync_utils, analysis_utils, nlx_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4183ec99",
   "metadata": {},
   "source": [
    "## Data loading and organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c43af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify root directory for un-archived data and results \n",
    "base_dir      = '/Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg/'\n",
    "anat_dir      = f'{base_dir}anat/'\n",
    "neural_dir    = f'{base_dir}/preprocess/clean_data/'\n",
    "subj_info_dir = f'{base_dir}patient_tracker/'\n",
    "\n",
    "subj_ids = list(pd.read_excel(f'{subj_info_dir}subjects_master_list.xlsx', usecols=[0]).PatientID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fcc9f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS001/MS001_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 304687 =      0.000 ...   609.374 secs\n",
      "Ready.\n",
      "Reading 0 ... 304687  =      0.000 ...   609.374 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS003/MS003_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 299894 =      0.000 ...   599.788 secs\n",
      "Ready.\n",
      "Reading 0 ... 299894  =      0.000 ...   599.788 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "1 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS006/MS006_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 303749 =      0.000 ...   607.498 secs\n",
      "Ready.\n",
      "Reading 0 ... 303749  =      0.000 ...   607.498 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS007/MS007_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 298949 =      0.000 ...   597.898 secs\n",
      "Ready.\n",
      "Reading 0 ... 298949  =      0.000 ...   597.898 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "10 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS008/MS008_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 331061 =      0.000 ...   662.122 secs\n",
      "Ready.\n",
      "Reading 0 ... 331061  =      0.000 ...   662.122 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS010/MS010_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 324718 =      0.000 ...   649.436 secs\n",
      "Ready.\n",
      "Reading 0 ... 324718  =      0.000 ...   649.436 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS012/MS012_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 309593 =      0.000 ...   619.186 secs\n",
      "Ready.\n",
      "Reading 0 ... 309593  =      0.000 ...   619.186 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS014/MS014_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 300811 =      0.000 ...   601.622 secs\n",
      "Ready.\n",
      "Reading 0 ... 300811  =      0.000 ...   601.622 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS016/MS016_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 337905 =      0.000 ...   675.810 secs\n",
      "Ready.\n",
      "Reading 0 ... 337905  =      0.000 ...   675.810 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS017/MS017_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 304229 =      0.000 ...   608.458 secs\n",
      "Ready.\n",
      "Reading 0 ... 304229  =      0.000 ...   608.458 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "1 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS018/MS018_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 308124 =      0.000 ...   616.248 secs\n",
      "Ready.\n",
      "Reading 0 ... 308124  =      0.000 ...   616.248 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS019/MS019_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 311530 =      0.000 ...   623.060 secs\n",
      "Ready.\n",
      "Reading 0 ... 311530  =      0.000 ...   623.060 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS020/MS020_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 329593 =      0.000 ...   659.186 secs\n",
      "Ready.\n",
      "Reading 0 ... 329593  =      0.000 ...   659.186 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS022/MS022_bp_ref_ieeg.fif...\n",
      "    Reading extended channel information\n",
      "    Range : 0 ... 320811 =      0.000 ...   641.622 secs\n",
      "Ready.\n",
      "Reading 0 ... 320811  =      0.000 ...   641.622 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS023/MS023_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 303249 =      0.000 ...   606.498 secs\n",
      "Ready.\n",
      "Reading 0 ... 303249  =      0.000 ...   606.498 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS024/MS024_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 303249 =      0.000 ...   606.498 secs\n",
      "Ready.\n",
      "Reading 0 ... 303249  =      0.000 ...   606.498 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS025/MS025_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 303718 =      0.000 ...   607.436 secs\n",
      "Ready.\n",
      "Reading 0 ... 303718  =      0.000 ...   607.436 secs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS026/MS026_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 226561 =      0.000 ...   453.122 secs\n",
      "Ready.\n",
      "Reading 0 ... 226561  =      0.000 ...   453.122 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS027/MS027_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 317874 =      0.000 ...   635.748 secs\n",
      "Ready.\n",
      "Reading 0 ... 317874  =      0.000 ...   635.748 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n",
      "Opening raw data file /Users/alexandrafink/Documents/GraduateSchool/SaezLab/resting_state_proj/resting_state_ieeg//preprocess/clean_data/MS028/MS028_bp_ref_ieeg.fif...\n",
      "    Range : 0 ... 305187 =      0.000 ...   610.374 secs\n",
      "Ready.\n",
      "Reading 0 ... 305187  =      0.000 ...   610.374 secs...\n",
      "Not setting metadata\n",
      "42 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 42 events and 5000 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "bp_lfp_all_subj = {}\n",
    "epochs_all_subj = {}\n",
    "\n",
    "\n",
    "for subj_id in subj_ids:\n",
    "    bp_data = mne.io.read_raw_fif(f'{neural_dir}{subj_id}/{subj_id}_bp_ref_ieeg.fif', preload=True)\n",
    "    bp_data.crop(tmin=10,tmax=430)\n",
    "    bp_lfp_all_subj[subj_id] = bp_data\n",
    "    epochs = mne.make_fixed_length_epochs(bp_data, duration=10, preload=True)\n",
    "    epochs_all_subj[subj_id] = epochs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2239e0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MS001': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~97.8 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS003': <Epochs |  41 events (all good), 0 - 9.998 sec, baseline off, ~125.3 MB, data loaded,\n",
       "  '1': 41>,\n",
       " 'MS006': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~115.5 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS007': <Epochs |  32 events (all good), 0 - 9.998 sec, baseline off, ~143.0 MB, data loaded,\n",
       "  '1': 32>,\n",
       " 'MS008': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~129.9 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS010': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~125.1 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS012': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~86.6 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS014': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~54.5 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS016': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~104.3 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS017': <Epochs |  41 events (all good), 0 - 9.998 sec, baseline off, ~90.8 MB, data loaded,\n",
       "  '1': 41>,\n",
       " 'MS018': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~149.2 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS019': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~110.7 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS020': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~112.3 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS022': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~56.1 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS023': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~162.0 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS024': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~163.6 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS025': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~146.0 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS026': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~121.9 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS027': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~134.7 MB, data loaded,\n",
       "  '1': 42>,\n",
       " 'MS028': <Epochs |  42 events (all good), 0 - 9.998 sec, baseline off, ~160.4 MB, data loaded,\n",
       "  '1': 42>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_all_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc2b1410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>1: 32</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>0.000 – 9.998 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>off</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Epochs |  32 events (all good), 0 - 9.998 sec, baseline off, ~143.0 MB, data loaded,\n",
       " '1': 32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_all_subj['MS007']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5085029c",
   "metadata": {},
   "source": [
    "## Epoching\n",
    "https://mne.tools/dev/generated/mne.make_fixed_length_epochs.html#mne.make_fixed_length_epochs\n",
    "https://mne.tools/dev/auto_tutorials/epochs/60_make_fixed_length_epochs.html#sphx-glr-auto-tutorials-epochs-60-make-fixed-length-epochs-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47335859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MS001': <Raw | MS001_bp_ref_ieeg.fif, 61 x 210001 (420.0 s), ~97.8 MB, data loaded>,\n",
       " 'MS003': <Raw | MS003_bp_ref_ieeg.fif, 80 x 210001 (420.0 s), ~128.3 MB, data loaded>,\n",
       " 'MS006': <Raw | MS006_bp_ref_ieeg.fif, 72 x 210001 (420.0 s), ~115.5 MB, data loaded>,\n",
       " 'MS007': <Raw | MS007_bp_ref_ieeg.fif, 117 x 210001 (420.0 s), ~187.6 MB, data loaded>,\n",
       " 'MS008': <Raw | MS008_bp_ref_ieeg.fif, 81 x 210001 (420.0 s), ~129.9 MB, data loaded>,\n",
       " 'MS010': <Raw | MS010_bp_ref_ieeg.fif, 78 x 210001 (420.0 s), ~125.1 MB, data loaded>,\n",
       " 'MS012': <Raw | MS012_bp_ref_ieeg.fif, 54 x 210001 (420.0 s), ~86.6 MB, data loaded>,\n",
       " 'MS014': <Raw | MS014_bp_ref_ieeg.fif, 34 x 210001 (420.0 s), ~54.5 MB, data loaded>,\n",
       " 'MS016': <Raw | MS016_bp_ref_ieeg.fif, 65 x 210001 (420.0 s), ~104.3 MB, data loaded>,\n",
       " 'MS017': <Raw | MS017_bp_ref_ieeg.fif, 58 x 210001 (420.0 s), ~93.0 MB, data loaded>,\n",
       " 'MS018': <Raw | MS018_bp_ref_ieeg.fif, 93 x 210001 (420.0 s), ~149.2 MB, data loaded>,\n",
       " 'MS019': <Raw | MS019_bp_ref_ieeg.fif, 69 x 210001 (420.0 s), ~110.7 MB, data loaded>,\n",
       " 'MS020': <Raw | MS020_bp_ref_ieeg.fif, 70 x 210001 (420.0 s), ~112.3 MB, data loaded>,\n",
       " 'MS022': <Raw | MS022_bp_ref_ieeg.fif, 35 x 210001 (420.0 s), ~56.1 MB, data loaded>,\n",
       " 'MS023': <Raw | MS023_bp_ref_ieeg.fif, 101 x 210001 (420.0 s), ~162.0 MB, data loaded>,\n",
       " 'MS024': <Raw | MS024_bp_ref_ieeg.fif, 102 x 210001 (420.0 s), ~163.6 MB, data loaded>,\n",
       " 'MS025': <Raw | MS025_bp_ref_ieeg.fif, 91 x 210001 (420.0 s), ~146.0 MB, data loaded>,\n",
       " 'MS026': <Raw | MS026_bp_ref_ieeg.fif, 76 x 210001 (420.0 s), ~121.9 MB, data loaded>,\n",
       " 'MS027': <Raw | MS027_bp_ref_ieeg.fif, 84 x 210001 (420.0 s), ~134.7 MB, data loaded>,\n",
       " 'MS028': <Raw | MS028_bp_ref_ieeg.fif, 100 x 210001 (420.0 s), ~160.4 MB, data loaded>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_lfp_all_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5237585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### make epochs \n",
    "\n",
    "#loop through subj\n",
    "#extract df \n",
    "#need to clip cont data into desired length raw.crop(0, 60).pick(picks=[\"mag\", \"stim\"]).load_data() ?\n",
    "\n",
    "\n",
    "\n",
    "epochs = mne.make_fixed_length_epochs(raw, duration=30, preload=False)\n",
    "#event_related_plot = epochs.plot_image(picks=[\"MEG 1142\"]) visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f64cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = len(clean_raw.ch_names) # get number of channels\n",
    "freq_master = np.zeros((77,)) # frequency - initialize list to store frequency for each channel\n",
    "psd_master = np.zeros((num_channels, 77)) # power spectral density - initialize list to store psd for each channel\n",
    "ch_names = clean_raw.ch_names # get channel names\n",
    "\n",
    "for channel in range(num_channels):\n",
    "    # compute power spectral density for each channel using welch method, median average, hann window, 2 second window, 50% overlap \n",
    "    freq, psd = compute_spectrum_welch(sig=clean_raw._data[channel,:], fs=sr, window='hann',avg_type='median',nperseg=sr*2,f_range=(2,40),noverlap=(sr*2)/2)\n",
    "    psd_master[channel,:] = psd \n",
    "    if channel == 0: # only need to get frequency once\n",
    "        freq_master[:,] = freq\n",
    "    else:\n",
    "        continue # continue to next channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some windows of interest \n",
    "\n",
    "buf = 1.0 # this is the buffer before and after that we use to limit edge effects for TFRs\n",
    "\n",
    "IED_args = {'peak_thresh':4,\n",
    "           'closeness_thresh':0.25, \n",
    "           'width_thresh':0.2}\n",
    "\n",
    "# evs = ['gamble_start', 'feedback_start', 'baseline_start']\n",
    "evs = {'gamble_start': [-1.0, 0.5],\n",
    "       'feedback_start': [-0.5, 1.5],\n",
    "       'baseline_start': [0, 0.75]}\n",
    "\n",
    "\n",
    "# add behavioral times of interest \n",
    "for subj_id in subj_ids:\n",
    "    # Set paths\n",
    "    load_path = f'{base_dir}/projects/guLab/Salman/EMU/{subj_id}/neural/Day1'\n",
    "    save_path = f'{base_dir}/projects/guLab/Salman/EphysAnalyses/{subj_id}/neural/Day1'\n",
    "\n",
    "    epochs_all_evs = {f'{x}': np.nan for x in evs}\n",
    "    for event in evs.keys():\n",
    "        pre = evs[event][0]\n",
    "        post = evs[event][1]\n",
    "        fixed_baseline = None\n",
    "        behav_times = learn_df[(learn_df.participant==subj_id)][event]\n",
    "\n",
    "        epochs = lfp_preprocess_utils.make_epochs(load_path=f'{save_path}/bp_ref_ieeg.fif', \n",
    "                                                  slope=slopes[subj_id][0], offset=offsets[subj_id][0], \n",
    "                                                  behav_name=event, behav_times=behav_times,\n",
    "                                                  ev_start_s=pre, ev_end_s=post, buf_s=1, downsamp_factor=None, IED_args=IED_args)\n",
    "\n",
    "\n",
    "        epochs_all_evs[event] = epochs\n",
    "        epochs_all_evs[event].save(f'{save_path}/{event}-epo.fif', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1b6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#things to consider:\n",
    "\n",
    "#do we want to add a buffer?\n",
    "#should epochs be overlapping?\n",
    "\n",
    "#epoch cleaning:\n",
    "# # 1/19/24: Let's also look for noisy epochs, which can persist even after notch filtering the whole session. \n",
    "# notch_freqs = [60] \n",
    "# notch_ranges = np.concatenate([np.arange(x-3,x+4) for x in notch_freqs]).flatten().tolist()\n",
    "# noisy_epochs_dict = {f'{x}':np.nan for x in ev_epochs.ch_names}\n",
    "\n",
    "# for ch_ in ev_epochs.ch_names:\n",
    "#     sig = ev_epochs.get_data(picks=[ch_])[:,0,:]\n",
    "#     noise_evs = []\n",
    "#     # compute the power spectrum\n",
    "#     freqs, psds = compute_spectrum(sig, ev_epochs.info['sfreq'], method='welch', avg_type='median')\n",
    "\n",
    "#     for event in np.arange(sig.shape[0]):\n",
    "#         # Find peaks in the power spectrum\n",
    "#         peaks, _ = find_peaks(np.log10(psds[event, :]), prominence=1.)  # Adjust threshold as needed\n",
    "#         peak_freqs = freqs[peaks]\n",
    "#         # do they intersect with noise ranges?\n",
    "#         intersection = set(peak_freqs) & set(notch_ranges)\n",
    "#         if intersection:\n",
    "#             noise_evs.append(event)\n",
    "#     ev_epochs.metadata.loc[noise_evs, ch_] = 'noise'\n",
    "#     # noisy_epochs_dict[ch_] = noise_evs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b1fadd",
   "metadata": {},
   "source": [
    "## Data Formatting + Saving for Connectivity Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7c9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://mne.tools/dev/auto_tutorials/preprocessing/30_filtering_resampling.html#tut-filter-resample\n",
    "epochs.load_data().filter(l_freq=8, h_freq=12)\n",
    "alpha_data = epochs.get_data(copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c878a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://mne.tools/mne-connectivity/stable/generated/mne_connectivity.spectral_connectivity_epochs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80065b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # choose the connectivity metric\n",
    "# metric = 'coh'  # ['coh', 'mic', 'mim', 'plv', 'ciplv', 'pli', 'wpli', 'gc', 'gc_tr']\n",
    "\n",
    "# band_dict = {'theta' : [2, 9],\n",
    "#                'beta' : [14, 30]}\n",
    "\n",
    "# freqs = np.logspace(*np.log10([2, 200]), num=30)\n",
    "# n_cycles = np.floor(np.logspace(*np.log10([3, 10]), num=30))\n",
    "\n",
    "# buf_ms = 1000\n",
    "# n_surr = 500\n",
    "\n",
    "# source_region = 'HPC'\n",
    "\n",
    "# # source_region = 'dmPFC'\n",
    "# # ['OFC', 'ACC', 'AMY']\n",
    "# # source_region = 'OFC'\n",
    "# # ['ACC', 'AMY']\n",
    "# # source_region = 'ACC'\n",
    "# # ['AMY']\n",
    "\n",
    "# # iterate through target regions\n",
    "# # analysis_evs = ['baseline_start']\n",
    "# analysis_evs = ['feedback_start', 'recog_time']\n",
    "\n",
    "\n",
    "# for target_region in ['OFC', 'AMY']: \n",
    "#     conn_group_data = []\n",
    "\n",
    "#     for subj_id in subj_ids:\n",
    "\n",
    "#         filepath = f'{base_dir}/projects/guLab/Salman/EphysAnalyses/{subj_id}/scratch/PSI'\n",
    "#         if not os.path.exists(filepath):\n",
    "#             os.makedirs(filepath)\n",
    "\n",
    "#         for event in analysis_evs:\n",
    "#             save_path = f'{base_dir}/projects/guLab/Salman/EphysAnalyses/{subj_id}/neural/{day}'\n",
    "#             epochs_reref = mne.read_epochs(f'{save_path}/{event}-epo.fif', preload=True) \n",
    "\n",
    "#             # Get electrode df \n",
    "#             elec_df = pd.read_csv(f'{base_dir}/projects/guLab/Salman/EphysAnalyses/{subj_id}/Day1_reref_elec_df')\n",
    "\n",
    "#             # construct the seed-to-target mapping based on your rois - matters most for PSI as this is directional \n",
    "#             seed_target_df = pd.DataFrame(columns=['seed', 'target'], index=['l', 'r'])\n",
    "#             for hemi in ['l', 'r']:\n",
    "#                 seed_target_df['seed'][hemi] = np.where(elec_df.loc[elec_df.hemisphere==hemi, 'salman_region'] == source_region)[0]\n",
    "# #                 seed_target_df['target'][hemi] = np.where(elec_df.loc[elec_df.hemisphere==hemi, 'salman_region'].isin(target_regions))[0]    \n",
    "\n",
    "#                 seed_target_df['target'][hemi] = np.where(elec_df.loc[elec_df.hemisphere==hemi, 'salman_region'] == target_region)[0]    \n",
    "\n",
    "#             seed_target_df = seed_target_df[\n",
    "#                         (seed_target_df['seed'].map(lambda d: len(d) > 0)) & (seed_target_df['target'].map(lambda d: len(d) > 0))]\n",
    "\n",
    "\n",
    "#             # for cond in conditions: \n",
    "#             for hemi in ['l', 'r']:\n",
    "#                 # first determine if ipsi connectivity is even possible; if not, move on\n",
    "#                 if hemi not in seed_target_df.index.tolist():\n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     seed_to_target = seed_target_indices(\n",
    "#                         seed_target_df['seed'][hemi],\n",
    "#                         seed_target_df['target'][hemi])\n",
    "                    \n",
    "                \n",
    "                    \n",
    "#                 # These epochs only grab those images that were later involved in memory recognition:\n",
    "#                 if event in ['gamble_start', 'feedback_start', 'baseline_start']:\n",
    "#                     epochs_to_analyze = combined_df[(combined_df.participant==subj_id) & (combined_df.condition=='Day1')].dropna(subset=['trials_gamble']).sort_values(by='trials_gamble').reset_index(drop=True).trials_gamble.values - 1\n",
    "#                 elif event == 'recog_time': \n",
    "#                     epochs_to_analyze = combined_df[(combined_df.participant==subj_id) & (combined_df.condition=='Day1')].dropna(subset=['trials_gamble']).sort_values(by='trials_mem').reset_index(drop=True).trials_mem.values - 1\n",
    "                    \n",
    "#                 trunc_epochs = epochs_reref[epochs_to_analyze.astype(int)]\n",
    "                \n",
    "#                 avg_dim = 'time'\n",
    "                \n",
    "#                 # NOTE: If I compute any epoch-avged connectivity measures, I need to NAN bad epochs BEFORE hand \n",
    "#                 npairs = len(seed_to_target[0])\n",
    "                \n",
    "# #                 for pair in range(npairs): \n",
    "# #                     source_bad_epochs  = list(np.where(trunc_epochs.metadata[trunc_epochs.ch_names[seed_to_target[0][pair]]].notnull())[0])\n",
    "# #                     target_bad_epochs  = list(np.where(trunc_epochs.metadata[trunc_epochs.ch_names[seed_to_target[1][pair]]].notnull())[0])\n",
    "# #                     bad_epochs = np.array(source_bad_epochs+target_bad_epochs)\n",
    "# #                     channels_involved = np.concatenate([np.unique(x) for x in seed_to_target])\n",
    "# #                     trunc_epochs._data[bad_epochs[:, np.newaxis], channels_involved, :] = 0\n",
    "                \n",
    "#                 pwise_dfs = []\n",
    "#                 for band in band_dict.keys():\n",
    "                \n",
    "#                     pwise = oscillation_utils.compute_connectivity(trunc_epochs, \n",
    "#                                                                band = band_dict[band], \n",
    "#                                                                metric = metric, \n",
    "#                                                                indices = seed_to_target, \n",
    "#                                                                freqs = freqs, \n",
    "#                                                                n_cycles = n_cycles,\n",
    "#                                                                buf_ms = buf_ms, \n",
    "#                                                                n_surr=n_surr,\n",
    "#                                                                avg_over_dim=avg_dim)\n",
    "\n",
    "#                     if avg_dim == 'epoch':\n",
    "#                         pwise = pwise[:, int(buf_ms  * (epochs_reref.info['sfreq']/1000)):-int(buf_ms  * (epochs_reref.info['sfreq']/1000))]\n",
    "\n",
    "#                     for pair in range(npairs): \n",
    "#                         pwise_df = pd.DataFrame(columns=['participant', 'roi1', 'roi2', 'hemi', 'pair_label', 'metric', 'event', 'conn'])\n",
    "#                         pwise_df['conn'] = pwise[:, pair] \n",
    "#                         pwise_df['participant'] = subj_id\n",
    "#                         pwise_df['age'] = subj_df[subj_df.MSSMCode==subj_id].Age.values[0]\n",
    "#                         pwise_df['sex'] = subj_df[subj_df.MSSMCode==subj_id].Sex.str.strip().values[0]\n",
    "\n",
    "#                         pwise_df['roi1'] = source_region\n",
    "#                         pwise_df['roi2'] = target_region\n",
    "#                         pwise_df['hemi'] = hemi \n",
    "#                         pwise_df['metric'] = metric \n",
    "#                         pwise_df['event'] = event\n",
    "#                         pwise_df['band'] = band\n",
    "#                         pwise_df['pair_label'] = f'{epochs_reref.ch_names[seed_to_target[0][pair]]}:{epochs_reref.ch_names[seed_to_target[1][pair]]}'\n",
    "#                         # pwise_df['trials'] = np.arange(1, pwise.shape[0]+1)\n",
    "#                         if event in ['gamble_start', 'feedback_start', 'baseline_start']:\n",
    "#                             pwise_df['trials_gamble'] = combined_df[(combined_df.participant==subj_id) & (combined_df.condition=='Day1')].dropna(subset=['trials_gamble']).sort_values(by='trials_gamble').reset_index(drop=True).trials_gamble.values\n",
    "#                             pwise_df = pwise_df.merge(combined_df[(combined_df.participant==subj_id) & (combined_df.condition=='Day1')].dropna(subset=['trials_gamble']).sort_values(by='trials_gamble').reset_index(drop=True), \n",
    "#                                                       on=['participant', 'trials_gamble'])\n",
    "#                         elif event == 'recog_time':\n",
    "#                             pwise_df['trials_mem'] = combined_df[(combined_df.participant==subj_id) & (combined_df.condition=='Day1')].dropna(subset=['trials_gamble']).sort_values(by='trials_mem').reset_index(drop=True).trials_mem.values\n",
    "#                             pwise_df = pwise_df.merge(combined_df[(combined_df.participant==subj_id) & (combined_df.condition=='Day1')].dropna(subset=['trials_gamble']).sort_values(by='trials_mem').reset_index(drop=True), \n",
    "#                                                       on=['participant', 'trials_mem'])\n",
    "\n",
    "#                         pwise_df['zrpe'] = (pwise_df.rpe - np.nanmean(pwise_df.rpe)) / (2*np.nanstd(pwise_df.rpe))\n",
    "#                         pwise_df['zpm'] = (pwise_df.DPRIME - np.nanmean(pwise_df.DPRIME)) / (2*np.nanstd(pwise_df.DPRIME))\n",
    "\n",
    "\n",
    "#                         pwise_df['good_epoch'] = 1\n",
    "#                         # NOTE: HOW TO HANDLE BAD EPOCHS? \n",
    "#                         # find all the bad epochs across both channels and add to the dataframe under pair label \n",
    "#                         # for ch_ix in progress_bar: \n",
    "#                         source_bad_epochs  = list(np.where(epochs_reref.metadata[epochs_reref.ch_names[seed_to_target[0][pair]]].notnull())[0])\n",
    "#                         target_bad_epochs  = list(np.where(epochs_reref.metadata[epochs_reref.ch_names[seed_to_target[1][pair]]].notnull())[0])\n",
    "#                         bad_epochs = np.array(source_bad_epochs+target_bad_epochs)\n",
    "#                         if event in ['gamble_start', 'feedback_start', 'baseline_start']:\n",
    "#                             pwise_df.loc[pwise_df['trials_gamble'].isin(bad_epochs), 'good_epoch'] = 0\n",
    "#                         elif event == 'recog_time':\n",
    "#                             pwise_df.loc[pwise_df['trials_mem'].isin(bad_epochs), 'good_epoch'] = 0\n",
    "                            \n",
    "#                         # aggregate\n",
    "#                         pwise_dfs.append(pwise_df)\n",
    "#                 pwise_dfs = pd.concat(pwise_dfs)\n",
    "#                 conn_group_data.append(pwise_dfs)\n",
    "\n",
    "#     all_pairs_df = pd.concat(conn_group_data)\n",
    "#     all_pairs_df.to_csv(f'/sc/arion/projects/guLab/Salman/EphysAnalyses/Connectivity/{source_region}_{target_region}_{metric}_df', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LFPAnalysis]",
   "language": "python",
   "name": "conda-env-LFPAnalysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
